{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple API Call with Requests Library\n",
    "\n",
    "It may be good to look at the reference documentation for the [requests library](https://2.python-requests.org/en/master/user/quickstart/).\n",
    "\n",
    "First, let's have a look at the [GitHub API](https://developer.github.com/v3/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://api.github.com/users/nmattei', timeout=10)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.headers['content-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at HTTP Requests\n",
    "\n",
    "We'll try to get some data from Google.  Note that this is kind of against the TOS and we **should not do it this way in general -- Google has very [specific rules on their site](https://developers.google.com/custom-search/v1/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'q':'Tulane University'}\n",
    "r = requests.get('http://www.google.com/search', params = params, timeout=10)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.headers['content-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Complicated with Parameters\n",
    "\n",
    "We'll look for some information from the [Apple ITunes API](https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'term' : \"the+meters\"}\n",
    "r = requests.get('https://itunes.apple.com/search', params=params, timeout=10)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do lots of parameters in the payload like [this](https://2.python-requests.org/en/master/user/quickstart/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'term' : \"the+meters\", 'entity' : 'album'}\n",
    "r = requests.get('https://itunes.apple.com/search', params=params, timeout=10)\n",
    "r.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['results'][0]['wrapperType']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the returned JSON to an object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['results'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Beautiful Soup to Parse a Webpage.\n",
    "\n",
    "The [beautifulsoup4 documentation](https://www.crummy.com/software/BeautifulSoup/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the course webpage.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r = requests.get('https://tulaneintrodatascience.github.io/')\n",
    "\n",
    "root = BeautifulSoup( r.content )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root.find(\"table\").findAll(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out some Regular Expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Find the index in the raw HTML where we first mention CMPS3660\n",
    "\n",
    "# Note we use the r to make sure special flags get used correctly.\n",
    "\n",
    "match = re.search(r'CMPS 3660', r.text)\n",
    "print(match.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.text[410:450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the start match?\n",
    "match = re.match(r'CMPS 3660', r.text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all occurances and print a few characters.\n",
    "for match in re.finditer(r'CMPS 3660', r.text):\n",
    "    print(r.text[match.start()-30:match.start()+20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find them all.\n",
    "match = re.findall(r'CMPS 3660', r.text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complicated RegExes - Groups\n",
    "regex = r'\\s*([Uu]niversity)\\s([Oo]f)\\s(\\w{3,})'\n",
    "text = ''' The university of kentucky is the best\n",
    "            basketball team and an ok university.\n",
    "            The University Of Kentucky can be put in \n",
    "            some weird capitalization'''\n",
    "m = re.search( regex, text)\n",
    "print(m.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all\n",
    "print(re.findall(regex, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named Groups.\n",
    "regex = r'\\s*([Uu]niversity)\\s([Oo]f)\\s(?P<school>\\w{3,})'\n",
    "text = ''' The university of kentucky is the best\n",
    "            basketball team and an ok university.\n",
    "            The University Of Kentucky can be put in \n",
    "            some weird capitalization'''\n",
    "m = re.search( regex, text)\n",
    "print(m.groupdict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all named groups\n",
    "\n",
    "# Named Groups.\n",
    "regex = r'\\s*([Uu]niversity)\\s([Oo]f)\\s(?P<school>\\w{3,})'\n",
    "text = ''' The university of kentucky is the best\n",
    "            basketball team and an ok university.\n",
    "            The University Of Kentucky can be put in \n",
    "            some weird capitalization.  And Kentucky is much better than\n",
    "            the University of Mississippi.'''\n",
    "for m in re.finditer(regex, text):\n",
    "    print(m.groupdict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'abcabcabc'.replace('a', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I love Introduction to Data Science'\n",
    "re.sub(r'Data Science', r'Schmada Schmience', text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r'(\\w+)\\s([Ss]cience)', r'\\2 \\1hmience', text) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloadning All the PDFs from the course website.\n",
    "\n",
    "Using beautiful soup and some regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urljoin\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HTTP GET request sent to the URL url\n",
    "url = \"https://tulaneintrodatascience.github.io/\"\n",
    "r = requests.get( url )\n",
    "\n",
    "# Use BeautifulSoup to parse the GET response\n",
    "root = BeautifulSoup( r.content )\n",
    "lnks = root.find(\"table\").find(\"tbody\").findAll(\"a\")\n",
    "lnks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through the href for each anchor, checking\n",
    "# to see if it's a PDF/PPTX link or not\n",
    "pdfs = []\n",
    "for lnk in lnks:\n",
    "    href = lnk['href']\n",
    "    \n",
    "    # If it's a PDF/PPTX link, queue a download   \n",
    "    if href.lower().endswith(('.pdf', '.pptx')):\n",
    "        pdfs.append(href)\n",
    "print(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the files to whatever you're running notebook from.\n",
    "\n",
    "# Be careful for href!\n",
    "\n",
    "for href in pdfs:\n",
    "    urld = urljoin(url, href)\n",
    "    print(urld)\n",
    "    rd = requests.get(urld, stream=True)\n",
    "    \n",
    "    # Write the downloaded PDF to a file\n",
    "    # Note because the href is a path we have to just get the filename!\n",
    "    outfile = os.path.join(\"./\", href.split(\"/\")[2])\n",
    "    print(\"Writing: \",outfile)\n",
    "    with open(outfile, 'wb') as f:\n",
    "        f.write(rd.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
